{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZhCInHWeKhE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rlMqA68kvJzS"
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "tmp1=[]\n",
    "tmp2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwAk_GXaKj0K"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(actual_classes : np.array, predicted_classes : np.array):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hdz3lGtLe7pY",
    "outputId": "c16a6bd5-b8d4-447a-9ad5-095fe39490a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EemWGFT1iN8f",
    "outputId": "403a97f0-abc9-4e74-9f16-9ceb838223d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 6.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 63.0 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 60.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "8ff4f3ceffd94f07aedb8964ae17ae23",
      "713ad769763c4202adab4ea6abe652c2",
      "7608dc94d1d44f64832cb2e1a546b7e9",
      "87c85f8ec7494da3a38e7660cfbc8d51",
      "925632f0757c4140ac014989a6ff9294",
      "cd969592c1ae4d59a48b645d9f928140",
      "f5151bbc6e74456b8cda1b579cf86c20",
      "f34bcc4ad0204537a4dc200a58cb9e69",
      "60e09cdcc9194f8a8a3698714c5b38cd",
      "bfab145dd5d346ed8775e3135af0c476",
      "6d5dd0093f674d9ca9a7cde27cbae8b5",
      "cd5d70abb3524cdab3b944dd526eb588",
      "e33ea59733af4253b59633287d3d431c",
      "93f68c8056e04380b666dffb71adfda1",
      "34a4455a785244e9ab998570c8d5dc47",
      "85efebbed86146d4b97c9f63aa75af6e",
      "8ff51db0e2354bf2aaf2aa293fc196dc",
      "558a192fab994a668432e6e467dbd83a",
      "6c1d26c956654c5592b1dfc27456e06b",
      "b295e5f0a65f4812a846c79110d6c3cc",
      "e5b16f42d1944db597a2d43165b59305",
      "f9416fcb106f4f73acd5f14d0b9e08dd",
      "0972184606d6419b82aee8c287a54902",
      "e6b10caf251c4cf984416c24b2eb6f50",
      "08d39d4473e249f79eb414ab513dd3da",
      "6354d425d93c4541864aee47cc5126b3",
      "d7ffc433ccb6417fbea4d91fb840a983",
      "fc2f38e57e114ba581abf13672fd9f54",
      "bd01e729cb8946beb0923634a91632a6",
      "c93737e3f25d4e0fb637a351de5e98e9",
      "75c12a52c084408faa49da709f903f9d",
      "f117b08a16fa42af99cb904d1dd92624",
      "dfe6c2b805b74895a6165cf8b6ec5ea7",
      "545072834b3b48a693cbf3b64dbdf306",
      "f972d57e96f7478ab284740acbc3937b",
      "6f80c20809424481b7150c140e9b319d",
      "b374eadace0140e1ba958d470d902bde",
      "5beca60916734c21b41b5e2c30ac8b83",
      "73c6994f01114ebb9fe789e8aab8598e",
      "7fd9fe6f1a5c4a72a38b7f44d1d2804c",
      "c54a81af6d2d4ed094b77ff9302626cb",
      "7f7b592822844de7ab2c8c6b295ecda0",
      "d3aae0530a074e29b4ac25de8b23281b",
      "f8e066702bc845b0b3d850977780f510"
     ]
    },
    "id": "ZzIxwRhrfJX7",
    "outputId": "38a02be2-24b5-4ac1-a833-742aeba7dbd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff4f3ceffd94f07aedb8964ae17ae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5d70abb3524cdab3b944dd526eb588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0972184606d6419b82aee8c287a54902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545072834b3b48a693cbf3b64dbdf306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import string \n",
    "import re\n",
    "\n",
    "#### text preprocessing\n",
    "def text_preprocessing(tweet):\n",
    "  tweet = re.sub('([@A-Za-z0-9]+)', '', tweet)\n",
    "\n",
    "  tweet = re.sub('_|ـ', ' ', tweet)\n",
    "\n",
    "  tweet = re.sub(r'(.)\\1\\1+', r'\\1', tweet)\n",
    "#  //normalization        \n",
    "  tweet = re.sub(\"[إأٱآا]\", \"ا\", tweet)\n",
    "  tweet = re.sub(\"ة\", \"ه\", tweet)\n",
    "  tweet = re.sub(\"ى\", \"ي\", tweet)\n",
    "  tweet = re.sub(\"ؤ\", \"ء\", tweet)\n",
    "  tweet = re.sub(\"ئ\", \"ء\", tweet)\n",
    "  tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "  return tweet \n",
    "\n",
    "#### bert preprocessing\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/MARBERT\")\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    MAX_LEN=250\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,\n",
    "            truncation =True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "b2b11cdc374f4409998a01fef891e6e0",
      "afad952ca5a94f8c82e32b973aede86d",
      "c238d460699543d6bdf3b610f43e3a1b",
      "a2388be6dd214be4bd038be5ba7ed722",
      "f55bb9008c4049fab8b288959e7307fa",
      "12015d613f294a6aa0bf4132432ca582",
      "9733b368628a4211ad48a0a0cfb3cec4",
      "68609e76bcfc41f483a5254b4a6cf04a",
      "9f89349e0d65470191ce5590e448a720",
      "f02b2a71302a41568c5e2e260a2f27f9",
      "5a8c7b5eb9c04e7b8795ca457bd421cd"
     ]
    },
    "id": "jzFtJ8GvpVDr",
    "outputId": "9b162eb6-6a1c-4bd8-c10e-13169e3ed533"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b11cdc374f4409998a01fef891e6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/624M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "MARBERT_model = AutoModel.from_pretrained(\"UBC-NLP/MARBERT\") \n",
    "\n",
    "# Bert-Classfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = AutoModel.from_pretrained(\"UBC-NLP/MARBERT\")\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n",
    "# Bert-Bilstm-Classfier class\n",
    "class BertBilstmClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False ):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set False to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertBilstmClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 2\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = AutoModel.from_pretrained(\"UBC-NLP/MARBERT\")\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2*H, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "        self.bilstm = nn.LSTM(D_in, H, batch_first = False, bidirectional=True)\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        a = outputs[0].tolist()\n",
    "        #print(\"size out of bert:\", np.array(a).shape)\n",
    "\n",
    "        output =  self.bilstm(outputs[0])\n",
    "        #print(\"output of BiLSTM \",len(list(outputs[0])))\n",
    "         # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHU_V3NTfXPB"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=2e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler\n",
    "def initialize_modelB(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertBilstmClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=2e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOP1JUKJjTRw"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    cm = False\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9}  | {'Val Acc':^9} |{'neg F1':^9} |{'pos F1':^9} |{'micro F1':^9} |{'macro F1':^9} |{'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "        if(epoch_i==1):\n",
    "          cm = True\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy ,val_neg_f1, val_pos_f1, microF1= evaluate(model, val_dataloader,cm)\n",
    "            macroF1= (val_neg_f1+ val_pos_f1)/2\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9f} | {val_neg_f1:^9f} |{val_pos_f1:^9f} |{microF1:^9f} |{macroF1:^9f} |{time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    return val_loss, val_accuracy ,val_neg_f1, val_pos_f1, microF1, macroF1\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader,cm):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    val_tp=[]\n",
    "    val_fp=[]\n",
    "    val_tn=[]\n",
    "    val_fn=[]\n",
    "    # tmp1=[]\n",
    "    # tmp2=[]\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        t1=b_labels\n",
    "        t2=preds\n",
    "        if(cm):\n",
    "          tmp1.extend(t1.cpu().numpy().astype(int))\n",
    "          tmp2.extend(t2.cpu().numpy().astype(int))\n",
    "\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "        val_tp.append((((preds+1)/(b_labels+1)) == b_labels).cpu().numpy().sum())\n",
    "        val_fp.append((preds - b_labels == 1).cpu().numpy().sum())\n",
    "        val_tn.append((((preds+1)/(b_labels+1)) == b_labels+1).cpu().numpy().sum())\n",
    "        val_fn.append((preds - b_labels == -1).cpu().numpy().sum())\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    val_tp=np.sum(val_tp)\n",
    "    val_fp=np.sum(val_fp)\n",
    "    val_tn=np.sum(val_tn)\n",
    "    val_fn=np.sum(val_fn)\n",
    "    pos= val_fn + val_tp\n",
    "    neg = val_fp +val_tn\n",
    "    total = pos + neg\n",
    "    # print(\"test micro \",f1_score(tmp1,tmp2,labels=[1,0],average=None))\n",
    "    print(pos, \"  \", neg, \"  \", total)\n",
    "    val_neg_f1=(2*val_tn)/( val_tn + val_fn +neg)\n",
    "    val_pos_f1=(2*val_tp)/( val_tp + val_fp +pos)\n",
    "    microF1 = (val_neg_f1 * neg + val_pos_f1 * pos)/ total\n",
    "    return val_loss, val_accuracy ,val_neg_f1, val_pos_f1, microF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PnR4B4auYbX",
    "outputId": "3a53491d-b8ec-4b60-b3f3-63b668ba0301"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------1-------------------------------------\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.413280   |     -      |     -     |   15.59  \n",
      "   1    |   40    |   0.096377   |     -      |     -     |   14.72  \n",
      "   1    |   60    |   0.120602   |     -      |     -     |   14.72  \n",
      "   1    |   80    |   0.111057   |     -      |     -     |   14.80  \n",
      "   1    |   100   |   0.091708   |     -      |     -     |   14.71  \n",
      "   1    |   120   |   0.092334   |     -      |     -     |   14.73  \n",
      "   1    |   140   |   0.054023   |     -      |     -     |   14.74  \n",
      "   1    |   160   |   0.099766   |     -      |     -     |   14.83  \n",
      "   1    |   180   |   0.099981   |     -      |     -     |   14.71  \n",
      "   1    |   200   |   0.078996   |     -      |     -     |   14.74  \n",
      "   1    |   220   |   0.096258   |     -      |     -     |   14.70  \n",
      "   1    |   240   |   0.081008   |     -      |     -     |   14.74  \n",
      "   1    |   260   |   0.069623   |     -      |     -     |   14.71  \n",
      "   1    |   280   |   0.040520   |     -      |     -     |   14.72  \n",
      "   1    |   300   |   0.078333   |     -      |     -     |   14.71  \n",
      "   1    |   320   |   0.097254   |     -      |     -     |   14.71  \n",
      "   1    |   340   |   0.062906   |     -      |     -     |   14.72  \n",
      "   1    |   348   |   0.072119   |     -      |     -     |   5.72   \n",
      "----------------------------------------------------------------------\n",
      "469    771    1240\n",
      "   1    |    -    |   0.105074   |  0.049017  | 98.878205 | 0.990909  |0.985106  |0.988714  |0.988008  | 266.17  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.028199   |     -      |     -     |   15.46  \n",
      "   2    |   40    |   0.029375   |     -      |     -     |   14.72  \n",
      "   2    |   60    |   0.041436   |     -      |     -     |   14.73  \n",
      "   2    |   80    |   0.040121   |     -      |     -     |   14.72  \n",
      "   2    |   100   |   0.009262   |     -      |     -     |   14.71  \n",
      "   2    |   120   |   0.005115   |     -      |     -     |   14.72  \n",
      "   2    |   140   |   0.026850   |     -      |     -     |   14.73  \n",
      "   2    |   160   |   0.022840   |     -      |     -     |   14.71  \n",
      "   2    |   180   |   0.033678   |     -      |     -     |   14.74  \n",
      "   2    |   200   |   0.016872   |     -      |     -     |   14.71  \n",
      "   2    |   220   |   0.048196   |     -      |     -     |   14.71  \n",
      "   2    |   240   |   0.017670   |     -      |     -     |   14.72  \n",
      "   2    |   260   |   0.036321   |     -      |     -     |   14.72  \n",
      "   2    |   280   |   0.039682   |     -      |     -     |   14.70  \n",
      "   2    |   300   |   0.030751   |     -      |     -     |   14.73  \n",
      "   2    |   320   |   0.028082   |     -      |     -     |   14.71  \n",
      "   2    |   340   |   0.034118   |     -      |     -     |   14.72  \n",
      "   2    |   348   |   0.056713   |     -      |     -     |   5.72   \n",
      "----------------------------------------------------------------------\n",
      "469    771    1240\n",
      "   2    |    -    |   0.029379   |  0.046865  | 98.878205 | 0.990933  |0.985043  |0.988705  |0.987988  | 265.85  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------2-------------------------------------\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.389620   |     -      |     -     |   15.46  \n",
      "   1    |   40    |   0.136798   |     -      |     -     |   14.72  \n",
      "   1    |   60    |   0.077940   |     -      |     -     |   14.70  \n",
      "   1    |   80    |   0.149941   |     -      |     -     |   14.72  \n",
      "   1    |   100   |   0.084214   |     -      |     -     |   14.70  \n",
      "   1    |   120   |   0.110976   |     -      |     -     |   14.73  \n",
      "   1    |   140   |   0.095640   |     -      |     -     |   14.71  \n",
      "   1    |   160   |   0.064030   |     -      |     -     |   14.73  \n",
      "   1    |   180   |   0.094714   |     -      |     -     |   14.72  \n",
      "   1    |   200   |   0.066147   |     -      |     -     |   14.73  \n",
      "   1    |   220   |   0.057360   |     -      |     -     |   14.72  \n",
      "   1    |   240   |   0.030801   |     -      |     -     |   14.71  \n",
      "   1    |   260   |   0.071577   |     -      |     -     |   14.73  \n",
      "   1    |   280   |   0.049401   |     -      |     -     |   14.72  \n",
      "   1    |   300   |   0.076302   |     -      |     -     |   14.73  \n",
      "   1    |   320   |   0.068067   |     -      |     -     |   14.70  \n",
      "   1    |   340   |   0.050791   |     -      |     -     |   14.75  \n",
      "   1    |   348   |   0.090920   |     -      |     -     |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "454    786    1240\n",
      "   1    |    -    |   0.099150   |  0.088957  | 97.836538 | 0.983290  |0.971861  |0.979106  |0.977576  | 265.85  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.036612   |     -      |     -     |   15.48  \n",
      "   2    |   40    |   0.054220   |     -      |     -     |   14.72  \n",
      "   2    |   60    |   0.021238   |     -      |     -     |   14.74  \n",
      "   2    |   80    |   0.040608   |     -      |     -     |   14.72  \n",
      "   2    |   100   |   0.036566   |     -      |     -     |   14.73  \n",
      "   2    |   120   |   0.043298   |     -      |     -     |   14.72  \n",
      "   2    |   140   |   0.048081   |     -      |     -     |   14.71  \n",
      "   2    |   160   |   0.038738   |     -      |     -     |   14.73  \n",
      "   2    |   180   |   0.023097   |     -      |     -     |   14.71  \n",
      "   2    |   200   |   0.024410   |     -      |     -     |   14.73  \n",
      "   2    |   220   |   0.010864   |     -      |     -     |   14.73  \n",
      "   2    |   240   |   0.035266   |     -      |     -     |   14.72  \n",
      "   2    |   260   |   0.021117   |     -      |     -     |   14.74  \n",
      "   2    |   280   |   0.047943   |     -      |     -     |   14.74  \n",
      "   2    |   300   |   0.012533   |     -      |     -     |   14.72  \n",
      "   2    |   320   |   0.016181   |     -      |     -     |   14.72  \n",
      "   2    |   340   |   0.014639   |     -      |     -     |   14.72  \n",
      "   2    |   348   |   0.048348   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "454    786    1240\n",
      "   2    |    -    |   0.031323   |  0.087022  | 97.836538 | 0.983355  |0.971678  |0.979079  |0.977516  | 265.98  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------3-------------------------------------\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.404204   |     -      |     -     |   15.47  \n",
      "   1    |   40    |   0.125396   |     -      |     -     |   14.72  \n",
      "   1    |   60    |   0.107342   |     -      |     -     |   14.72  \n",
      "   1    |   80    |   0.103200   |     -      |     -     |   14.73  \n",
      "   1    |   100   |   0.046032   |     -      |     -     |   14.75  \n",
      "   1    |   120   |   0.082275   |     -      |     -     |   14.74  \n",
      "   1    |   140   |   0.108937   |     -      |     -     |   14.71  \n",
      "   1    |   160   |   0.117089   |     -      |     -     |   14.71  \n",
      "   1    |   180   |   0.062906   |     -      |     -     |   14.72  \n",
      "   1    |   200   |   0.113835   |     -      |     -     |   14.73  \n",
      "   1    |   220   |   0.079290   |     -      |     -     |   14.72  \n",
      "   1    |   240   |   0.076893   |     -      |     -     |   14.72  \n",
      "   1    |   260   |   0.094230   |     -      |     -     |   14.72  \n",
      "   1    |   280   |   0.077159   |     -      |     -     |   14.74  \n",
      "   1    |   300   |   0.063153   |     -      |     -     |   14.71  \n",
      "   1    |   320   |   0.055324   |     -      |     -     |   14.72  \n",
      "   1    |   340   |   0.050427   |     -      |     -     |   14.72  \n",
      "   1    |   348   |   0.048689   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "462    778    1240\n",
      "   1    |    -    |   0.103575   |  0.063523  | 98.397436 | 0.987113  |0.978448  |0.983885  |0.982781  | 265.92  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.025741   |     -      |     -     |   15.47  \n",
      "   2    |   40    |   0.029350   |     -      |     -     |   14.73  \n",
      "   2    |   60    |   0.039520   |     -      |     -     |   14.74  \n",
      "   2    |   80    |   0.018265   |     -      |     -     |   14.71  \n",
      "   2    |   100   |   0.016682   |     -      |     -     |   14.73  \n",
      "   2    |   120   |   0.013662   |     -      |     -     |   14.74  \n",
      "   2    |   140   |   0.038526   |     -      |     -     |   14.74  \n",
      "   2    |   160   |   0.005041   |     -      |     -     |   14.73  \n",
      "   2    |   180   |   0.032784   |     -      |     -     |   14.72  \n",
      "   2    |   200   |   0.020508   |     -      |     -     |   14.74  \n",
      "   2    |   220   |   0.045817   |     -      |     -     |   14.72  \n",
      "   2    |   240   |   0.019283   |     -      |     -     |   14.74  \n",
      "   2    |   260   |   0.009547   |     -      |     -     |   14.72  \n",
      "   2    |   280   |   0.037837   |     -      |     -     |   14.71  \n",
      "   2    |   300   |   0.040134   |     -      |     -     |   14.71  \n",
      "   2    |   320   |   0.024861   |     -      |     -     |   14.72  \n",
      "   2    |   340   |   0.011084   |     -      |     -     |   14.73  \n",
      "   2    |   348   |   0.014232   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "462    778    1240\n",
      "   2    |    -    |   0.024964   |  0.065342  | 98.477564 | 0.987766  |0.979504  |0.984687  |0.983635  | 265.96  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------4-------------------------------------\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.388813   |     -      |     -     |   15.46  \n",
      "   1    |   40    |   0.148580   |     -      |     -     |   14.72  \n",
      "   1    |   60    |   0.140885   |     -      |     -     |   14.72  \n",
      "   1    |   80    |   0.122290   |     -      |     -     |   14.71  \n",
      "   1    |   100   |   0.106908   |     -      |     -     |   14.73  \n",
      "   1    |   120   |   0.074235   |     -      |     -     |   14.73  \n",
      "   1    |   140   |   0.094213   |     -      |     -     |   14.71  \n",
      "   1    |   160   |   0.070092   |     -      |     -     |   14.71  \n",
      "   1    |   180   |   0.081261   |     -      |     -     |   14.72  \n",
      "   1    |   200   |   0.044431   |     -      |     -     |   14.73  \n",
      "   1    |   220   |   0.056145   |     -      |     -     |   14.73  \n",
      "   1    |   240   |   0.086001   |     -      |     -     |   14.72  \n",
      "   1    |   260   |   0.081340   |     -      |     -     |   14.74  \n",
      "   1    |   280   |   0.085113   |     -      |     -     |   14.71  \n",
      "   1    |   300   |   0.105848   |     -      |     -     |   14.73  \n",
      "   1    |   320   |   0.059675   |     -      |     -     |   14.71  \n",
      "   1    |   340   |   0.054738   |     -      |     -     |   14.73  \n",
      "   1    |   348   |   0.034849   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "451    789    1240\n",
      "   1    |    -    |   0.105097   |  0.058626  | 98.450855 | 0.987997  |0.978818  |0.984659  |0.983408  | 265.88  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.031664   |     -      |     -     |   15.44  \n",
      "   2    |   40    |   0.038745   |     -      |     -     |   14.74  \n",
      "   2    |   60    |   0.033359   |     -      |     -     |   14.75  \n",
      "   2    |   80    |   0.071977   |     -      |     -     |   14.73  \n",
      "   2    |   100   |   0.028996   |     -      |     -     |   14.71  \n",
      "   2    |   120   |   0.039824   |     -      |     -     |   14.72  \n",
      "   2    |   140   |   0.049056   |     -      |     -     |   14.72  \n",
      "   2    |   160   |   0.019853   |     -      |     -     |   14.73  \n",
      "   2    |   180   |   0.024047   |     -      |     -     |   14.73  \n",
      "   2    |   200   |   0.048013   |     -      |     -     |   14.73  \n",
      "   2    |   220   |   0.048171   |     -      |     -     |   14.73  \n",
      "   2    |   240   |   0.023321   |     -      |     -     |   14.73  \n",
      "   2    |   260   |   0.021663   |     -      |     -     |   14.74  \n",
      "   2    |   280   |   0.028576   |     -      |     -     |   14.73  \n",
      "   2    |   300   |   0.034607   |     -      |     -     |   14.73  \n",
      "   2    |   320   |   0.007347   |     -      |     -     |   14.72  \n",
      "   2    |   340   |   0.033531   |     -      |     -     |   14.73  \n",
      "   2    |   348   |   0.004002   |     -      |     -     |   5.72   \n",
      "----------------------------------------------------------------------\n",
      "451    789    1240\n",
      "   2    |    -    |   0.033578   |  0.060959  | 98.637821 | 0.989261  |0.981048  |0.986274  |0.985154  | 265.93  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------5-------------------------------------\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.382422   |     -      |     -     |   15.47  \n",
      "   1    |   40    |   0.148598   |     -      |     -     |   14.72  \n",
      "   1    |   60    |   0.107499   |     -      |     -     |   14.73  \n",
      "   1    |   80    |   0.101282   |     -      |     -     |   14.72  \n",
      "   1    |   100   |   0.145420   |     -      |     -     |   14.75  \n",
      "   1    |   120   |   0.081204   |     -      |     -     |   14.73  \n",
      "   1    |   140   |   0.143439   |     -      |     -     |   14.73  \n",
      "   1    |   160   |   0.090790   |     -      |     -     |   14.72  \n",
      "   1    |   180   |   0.068798   |     -      |     -     |   14.73  \n",
      "   1    |   200   |   0.067913   |     -      |     -     |   14.73  \n",
      "   1    |   220   |   0.090864   |     -      |     -     |   14.71  \n",
      "   1    |   240   |   0.082119   |     -      |     -     |   14.76  \n",
      "   1    |   260   |   0.079792   |     -      |     -     |   14.71  \n",
      "   1    |   280   |   0.081760   |     -      |     -     |   14.73  \n",
      "   1    |   300   |   0.046256   |     -      |     -     |   14.71  \n",
      "   1    |   320   |   0.039228   |     -      |     -     |   14.74  \n",
      "   1    |   340   |   0.053182   |     -      |     -     |   14.71  \n",
      "   1    |   348   |   0.063984   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "460    780    1240\n",
      "   1    |    -    |   0.106320   |  0.097431  | 97.889957 | 0.983355  |0.971678  |0.979023  |0.977516  | 265.97  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.031293   |     -      |     -     |   15.45  \n",
      "   2    |   40    |   0.020127   |     -      |     -     |   14.72  \n",
      "   2    |   60    |   0.080186   |     -      |     -     |   14.72  \n",
      "   2    |   80    |   0.039050   |     -      |     -     |   14.73  \n",
      "   2    |   100   |   0.026966   |     -      |     -     |   14.73  \n",
      "   2    |   120   |   0.012698   |     -      |     -     |   14.74  \n",
      "   2    |   140   |   0.038221   |     -      |     -     |   14.74  \n",
      "   2    |   160   |   0.019655   |     -      |     -     |   14.73  \n",
      "   2    |   180   |   0.030195   |     -      |     -     |   14.73  \n",
      "   2    |   200   |   0.057973   |     -      |     -     |   14.74  \n",
      "   2    |   220   |   0.017143   |     -      |     -     |   14.71  \n",
      "   2    |   240   |   0.031424   |     -      |     -     |   14.73  \n",
      "   2    |   260   |   0.019960   |     -      |     -     |   14.72  \n",
      "   2    |   280   |   0.017479   |     -      |     -     |   14.73  \n",
      "   2    |   300   |   0.016677   |     -      |     -     |   14.72  \n",
      "   2    |   320   |   0.043044   |     -      |     -     |   14.73  \n",
      "   2    |   340   |   0.006691   |     -      |     -     |   14.73  \n",
      "   2    |   348   |   0.055079   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "460    780    1240\n",
      "   2    |    -    |   0.030509   |  0.089902  | 98.210470 | 0.985897  |0.976087  |0.982258  |0.980992  | 265.97  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------6-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.372033   |     -      |     -     |   15.46  \n",
      "   1    |   40    |   0.160480   |     -      |     -     |   14.73  \n",
      "   1    |   60    |   0.131927   |     -      |     -     |   14.73  \n",
      "   1    |   80    |   0.090012   |     -      |     -     |   14.74  \n",
      "   1    |   100   |   0.106762   |     -      |     -     |   14.75  \n",
      "   1    |   120   |   0.074537   |     -      |     -     |   14.74  \n",
      "   1    |   140   |   0.058737   |     -      |     -     |   14.74  \n",
      "   1    |   160   |   0.126155   |     -      |     -     |   14.73  \n",
      "   1    |   180   |   0.065838   |     -      |     -     |   14.73  \n",
      "   1    |   200   |   0.099047   |     -      |     -     |   14.71  \n",
      "   1    |   220   |   0.069971   |     -      |     -     |   14.74  \n",
      "   1    |   240   |   0.083870   |     -      |     -     |   14.73  \n",
      "   1    |   260   |   0.048922   |     -      |     -     |   14.73  \n",
      "   1    |   280   |   0.077543   |     -      |     -     |   14.73  \n",
      "   1    |   300   |   0.057853   |     -      |     -     |   14.71  \n",
      "   1    |   320   |   0.070939   |     -      |     -     |   14.73  \n",
      "   1    |   340   |   0.073386   |     -      |     -     |   14.71  \n",
      "   1    |   348   |   0.055648   |     -      |     -     |   5.72   \n",
      "----------------------------------------------------------------------\n",
      "458    782    1240\n",
      "   1    |    -    |   0.103660   |  0.051753  | 98.664530 | 0.989744  |0.982609  |0.987108  |0.986176  | 266.03  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.031414   |     -      |     -     |   15.47  \n",
      "   2    |   40    |   0.029087   |     -      |     -     |   14.74  \n",
      "   2    |   60    |   0.026805   |     -      |     -     |   14.74  \n",
      "   2    |   80    |   0.032623   |     -      |     -     |   14.72  \n",
      "   2    |   100   |   0.058199   |     -      |     -     |   14.74  \n",
      "   2    |   120   |   0.021619   |     -      |     -     |   14.72  \n",
      "   2    |   140   |   0.043213   |     -      |     -     |   14.73  \n",
      "   2    |   160   |   0.030073   |     -      |     -     |   14.74  \n",
      "   2    |   180   |   0.037879   |     -      |     -     |   14.72  \n",
      "   2    |   200   |   0.004351   |     -      |     -     |   14.73  \n",
      "   2    |   220   |   0.031636   |     -      |     -     |   14.74  \n",
      "   2    |   240   |   0.032705   |     -      |     -     |   14.69  \n",
      "   2    |   260   |   0.027751   |     -      |     -     |   14.72  \n",
      "   2    |   280   |   0.019836   |     -      |     -     |   14.72  \n",
      "   2    |   300   |   0.018929   |     -      |     -     |   14.73  \n",
      "   2    |   320   |   0.040483   |     -      |     -     |   14.72  \n",
      "   2    |   340   |   0.031203   |     -      |     -     |   14.73  \n",
      "   2    |   348   |   0.026270   |     -      |     -     |   5.72   \n",
      "----------------------------------------------------------------------\n",
      "458    782    1240\n",
      "   2    |    -    |   0.030366   |  0.058056  | 98.637821 | 0.989757  |0.982571  |0.987103  |0.986164  | 265.95  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------7-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.391544   |     -      |     -     |   15.48  \n",
      "   1    |   40    |   0.131548   |     -      |     -     |   14.74  \n",
      "   1    |   60    |   0.131906   |     -      |     -     |   14.72  \n",
      "   1    |   80    |   0.081462   |     -      |     -     |   14.72  \n",
      "   1    |   100   |   0.109372   |     -      |     -     |   14.71  \n",
      "   1    |   120   |   0.070356   |     -      |     -     |   14.72  \n",
      "   1    |   140   |   0.075756   |     -      |     -     |   14.73  \n",
      "   1    |   160   |   0.097755   |     -      |     -     |   14.73  \n",
      "   1    |   180   |   0.113813   |     -      |     -     |   14.72  \n",
      "   1    |   200   |   0.081393   |     -      |     -     |   14.75  \n",
      "   1    |   220   |   0.066014   |     -      |     -     |   14.73  \n",
      "   1    |   240   |   0.110560   |     -      |     -     |   14.74  \n",
      "   1    |   260   |   0.032681   |     -      |     -     |   14.75  \n",
      "   1    |   280   |   0.047730   |     -      |     -     |   14.73  \n",
      "   1    |   300   |   0.066221   |     -      |     -     |   14.72  \n",
      "   1    |   320   |   0.066253   |     -      |     -     |   14.74  \n",
      "   1    |   340   |   0.114873   |     -      |     -     |   14.72  \n",
      "   1    |   348   |   0.080334   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "418    822    1240\n",
      "   1    |    -    |   0.105499   |  0.048487  | 98.931624 | 0.992097  |0.984431  |0.989513  |0.988264  | 266.02  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.041231   |     -      |     -     |   15.46  \n",
      "   2    |   40    |   0.013476   |     -      |     -     |   14.74  \n",
      "   2    |   60    |   0.037616   |     -      |     -     |   14.74  \n",
      "   2    |   80    |   0.024090   |     -      |     -     |   14.74  \n",
      "   2    |   100   |   0.036157   |     -      |     -     |   14.75  \n",
      "   2    |   120   |   0.033543   |     -      |     -     |   14.71  \n",
      "   2    |   140   |   0.020790   |     -      |     -     |   14.73  \n",
      "   2    |   160   |   0.023965   |     -      |     -     |   14.72  \n",
      "   2    |   180   |   0.037616   |     -      |     -     |   14.72  \n",
      "   2    |   200   |   0.029351   |     -      |     -     |   14.74  \n",
      "   2    |   220   |   0.014091   |     -      |     -     |   14.73  \n",
      "   2    |   240   |   0.035630   |     -      |     -     |   14.74  \n",
      "   2    |   260   |   0.029635   |     -      |     -     |   14.73  \n",
      "   2    |   280   |   0.017798   |     -      |     -     |   14.72  \n",
      "   2    |   300   |   0.050333   |     -      |     -     |   14.74  \n",
      "   2    |   320   |   0.038863   |     -      |     -     |   14.73  \n",
      "   2    |   340   |   0.023732   |     -      |     -     |   14.73  \n",
      "   2    |   348   |   0.027058   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "418    822    1240\n",
      "   2    |    -    |   0.029845   |  0.063208  | 98.263889 | 0.987187  |0.975030  |0.983089  |0.981109  | 266.02  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------8-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.404053   |     -      |     -     |   15.48  \n",
      "   1    |   40    |   0.147912   |     -      |     -     |   14.74  \n",
      "   1    |   60    |   0.095635   |     -      |     -     |   14.72  \n",
      "   1    |   80    |   0.154962   |     -      |     -     |   14.73  \n",
      "   1    |   100   |   0.086963   |     -      |     -     |   14.74  \n",
      "   1    |   120   |   0.061171   |     -      |     -     |   14.74  \n",
      "   1    |   140   |   0.053215   |     -      |     -     |   14.73  \n",
      "   1    |   160   |   0.065638   |     -      |     -     |   14.73  \n",
      "   1    |   180   |   0.085355   |     -      |     -     |   14.72  \n",
      "   1    |   200   |   0.086907   |     -      |     -     |   14.76  \n",
      "   1    |   220   |   0.115631   |     -      |     -     |   14.72  \n",
      "   1    |   240   |   0.040629   |     -      |     -     |   14.75  \n",
      "   1    |   260   |   0.061772   |     -      |     -     |   14.73  \n",
      "   1    |   280   |   0.062440   |     -      |     -     |   14.74  \n",
      "   1    |   300   |   0.067671   |     -      |     -     |   14.75  \n",
      "   1    |   320   |   0.109366   |     -      |     -     |   14.73  \n",
      "   1    |   340   |   0.057324   |     -      |     -     |   14.73  \n",
      "   1    |   348   |   0.086461   |     -      |     -     |   5.71   \n",
      "----------------------------------------------------------------------\n",
      "454    786    1240\n",
      "   1    |    -    |   0.103807   |  0.050265  | 98.878205 | 0.991026  |0.984783  |0.988740  |0.987904  | 266.10  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.028427   |     -      |     -     |   15.46  \n",
      "   2    |   40    |   0.026262   |     -      |     -     |   14.76  \n",
      "   2    |   60    |   0.021317   |     -      |     -     |   14.75  \n",
      "   2    |   80    |   0.027566   |     -      |     -     |   14.74  \n",
      "   2    |   100   |   0.041155   |     -      |     -     |   14.73  \n",
      "   2    |   120   |   0.011553   |     -      |     -     |   14.74  \n",
      "   2    |   140   |   0.027106   |     -      |     -     |   14.73  \n",
      "   2    |   160   |   0.034772   |     -      |     -     |   14.72  \n",
      "   2    |   180   |   0.035466   |     -      |     -     |   14.74  \n",
      "   2    |   200   |   0.024724   |     -      |     -     |   14.72  \n",
      "   2    |   220   |   0.020659   |     -      |     -     |   14.74  \n",
      "   2    |   240   |   0.003799   |     -      |     -     |   14.75  \n",
      "   2    |   260   |   0.042391   |     -      |     -     |   14.73  \n",
      "   2    |   280   |   0.045127   |     -      |     -     |   14.73  \n",
      "   2    |   300   |   0.017863   |     -      |     -     |   14.74  \n",
      "   2    |   320   |   0.034825   |     -      |     -     |   14.76  \n",
      "   2    |   340   |   0.029862   |     -      |     -     |   14.75  \n",
      "   2    |   348   |   0.023465   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "454    786    1240\n",
      "   2    |    -    |   0.027718   |  0.043188  | 98.878205 | 0.991037  |0.984749  |0.988735  |0.987893  | 266.16  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------9-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.408716   |     -      |     -     |   15.47  \n",
      "   1    |   40    |   0.131568   |     -      |     -     |   14.75  \n",
      "   1    |   60    |   0.177763   |     -      |     -     |   14.75  \n",
      "   1    |   80    |   0.097148   |     -      |     -     |   14.74  \n",
      "   1    |   100   |   0.110350   |     -      |     -     |   14.74  \n",
      "   1    |   120   |   0.191093   |     -      |     -     |   14.76  \n",
      "   1    |   140   |   0.086627   |     -      |     -     |   14.75  \n",
      "   1    |   160   |   0.095086   |     -      |     -     |   14.74  \n",
      "   1    |   180   |   0.092212   |     -      |     -     |   14.75  \n",
      "   1    |   200   |   0.080576   |     -      |     -     |   14.75  \n",
      "   1    |   220   |   0.072334   |     -      |     -     |   14.74  \n",
      "   1    |   240   |   0.044308   |     -      |     -     |   14.76  \n",
      "   1    |   260   |   0.058225   |     -      |     -     |   14.75  \n",
      "   1    |   280   |   0.047784   |     -      |     -     |   14.75  \n",
      "   1    |   300   |   0.086380   |     -      |     -     |   14.74  \n",
      "   1    |   320   |   0.065250   |     -      |     -     |   14.75  \n",
      "   1    |   340   |   0.036503   |     -      |     -     |   14.75  \n",
      "   1    |   348   |   0.047167   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "448    792    1240\n",
      "   1    |    -    |   0.110099   |  0.063133  | 98.477564 | 0.988088  |0.978531  |0.984635  |0.983309  | 266.30  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.029534   |     -      |     -     |   15.48  \n",
      "   2    |   40    |   0.015256   |     -      |     -     |   14.74  \n",
      "   2    |   60    |   0.019882   |     -      |     -     |   14.75  \n",
      "   2    |   80    |   0.007808   |     -      |     -     |   14.74  \n",
      "   2    |   100   |   0.050487   |     -      |     -     |   14.75  \n",
      "   2    |   120   |   0.043739   |     -      |     -     |   14.75  \n",
      "   2    |   140   |   0.024609   |     -      |     -     |   14.76  \n",
      "   2    |   160   |   0.026995   |     -      |     -     |   14.75  \n",
      "   2    |   180   |   0.023221   |     -      |     -     |   14.78  \n",
      "   2    |   200   |   0.038713   |     -      |     -     |   14.75  \n",
      "   2    |   220   |   0.033229   |     -      |     -     |   14.75  \n",
      "   2    |   240   |   0.030341   |     -      |     -     |   14.75  \n",
      "   2    |   260   |   0.032395   |     -      |     -     |   14.76  \n",
      "   2    |   280   |   0.017908   |     -      |     -     |   14.76  \n",
      "   2    |   300   |   0.033375   |     -      |     -     |   14.77  \n",
      "   2    |   320   |   0.020451   |     -      |     -     |   14.74  \n",
      "   2    |   340   |   0.011862   |     -      |     -     |   14.76  \n",
      "   2    |   348   |   0.079963   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "448    792    1240\n",
      "   2    |    -    |   0.028268   |  0.065696  | 98.530983 | 0.988693  |0.979730  |0.985455  |0.984212  | 266.39  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "--------------------------------10-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.419950   |     -      |     -     |   15.51  \n",
      "   1    |   40    |   0.120730   |     -      |     -     |   14.77  \n",
      "   1    |   60    |   0.079612   |     -      |     -     |   14.77  \n",
      "   1    |   80    |   0.083515   |     -      |     -     |   14.77  \n",
      "   1    |   100   |   0.101459   |     -      |     -     |   14.74  \n",
      "   1    |   120   |   0.130588   |     -      |     -     |   14.76  \n",
      "   1    |   140   |   0.121487   |     -      |     -     |   14.75  \n",
      "   1    |   160   |   0.123085   |     -      |     -     |   14.74  \n",
      "   1    |   180   |   0.083431   |     -      |     -     |   14.77  \n",
      "   1    |   200   |   0.079521   |     -      |     -     |   14.76  \n",
      "   1    |   220   |   0.060289   |     -      |     -     |   14.76  \n",
      "   1    |   240   |   0.051582   |     -      |     -     |   14.76  \n",
      "   1    |   260   |   0.069932   |     -      |     -     |   14.76  \n",
      "   1    |   280   |   0.053152   |     -      |     -     |   14.79  \n",
      "   1    |   300   |   0.053970   |     -      |     -     |   14.76  \n",
      "   1    |   320   |   0.048242   |     -      |     -     |   14.77  \n",
      "   1    |   340   |   0.054120   |     -      |     -     |   14.76  \n",
      "   1    |   348   |   0.104622   |     -      |     -     |   5.73   \n",
      "----------------------------------------------------------------------\n",
      "477    763    1240\n",
      "   1    |    -    |   0.103009   |  0.055546  | 98.637821 | 0.988867  |0.982162  |0.986288  |0.985514  | 266.58  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc   |  Val Acc  | neg F1   | pos F1   |micro F1  |macro F1  | Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.044085   |     -      |     -     |   15.52  \n",
      "   2    |   40    |   0.023744   |     -      |     -     |   14.77  \n",
      "   2    |   60    |   0.021671   |     -      |     -     |   14.76  \n",
      "   2    |   80    |   0.024339   |     -      |     -     |   14.77  \n",
      "   2    |   100   |   0.037256   |     -      |     -     |   14.76  \n",
      "   2    |   120   |   0.033145   |     -      |     -     |   14.76  \n",
      "   2    |   140   |   0.035385   |     -      |     -     |   14.76  \n",
      "   2    |   160   |   0.025267   |     -      |     -     |   14.77  \n",
      "   2    |   180   |   0.021995   |     -      |     -     |   14.79  \n",
      "   2    |   200   |   0.050092   |     -      |     -     |   14.78  \n",
      "   2    |   220   |   0.043143   |     -      |     -     |   14.78  \n",
      "   2    |   240   |   0.033921   |     -      |     -     |   14.78  \n",
      "   2    |   260   |   0.012375   |     -      |     -     |   14.76  \n",
      "   2    |   280   |   0.015818   |     -      |     -     |   14.75  \n",
      "   2    |   300   |   0.044840   |     -      |     -     |   14.77  \n",
      "   2    |   320   |   0.037877   |     -      |     -     |   14.78  \n",
      "   2    |   340   |   0.016927   |     -      |     -     |   14.77  \n",
      "   2    |   348   |   0.039230   |     -      |     -     |   5.75   \n",
      "----------------------------------------------------------------------\n",
      "477    763    1240\n",
      "   2    |    -    |   0.030933   |  0.050326  | 98.717949 | 0.989529  |0.983193  |0.987092  |0.986361  | 266.74  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n",
      "  Avg Loss  | Avg Acc   | avg neg F1|avg pos F1 |avg micro F1 |avg macro F1 \n",
      "  0.063056  | 98.506944 | 0.988341  |0.979863  |0.985248  |0.984102  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "      #Loading data\n",
    "data = pd.read_csv('finalDataset2.csv')\n",
    "#data['finalLabel'] = data['finalLabel'].replace([-1],0)\n",
    "\n",
    "X = data.tweet.values\n",
    "#y = data.finalLabel.values\n",
    "y = data.Label.values\n",
    "y=y.astype(int)\n",
    "### converting labels to tensors and intilizing batches\n",
    "labels = torch.tensor(y)\n",
    "MAX_LEN = 250\n",
    "print('Tokenizing data...')\n",
    "inputs, masks = preprocessing_for_bert(X)\n",
    "acc_per_fold=[]\n",
    "loss_per_fold=[]\n",
    "neg_f1_per_fold=[]\n",
    "pos_f1_per_fold=[]\n",
    "micro_f1_per_fold=[]\n",
    "macro_f1_per_fold=[]\n",
    "noFold = 0\n",
    "\n",
    "for train_index , val_index in KFold(n_splits=10, random_state=None, shuffle=True).split(X): \n",
    "  train_inputs = inputs[train_index]\n",
    "  train_masks = masks[train_index]\n",
    "  train_labels = labels[train_index]\n",
    "  val_inputs = inputs[val_index]\n",
    "  val_masks = masks[val_index]\n",
    "  val_labels = labels[val_index]\n",
    "  noFold = noFold + 1\n",
    "      \n",
    "  print(f\"--------------------------------{noFold}-------------------------------------\")      \n",
    "\n",
    "      #splitting Data\n",
    "# X_train, X_val, y_train, y_val =\\\n",
    "#     train_test_split(X, y, test_size=0.1, random_state=2020)\n",
    "#       #Tokenizing\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "  batch_size = 32\n",
    "\n",
    "  # Create the DataLoader for our training set\n",
    "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "  train_sampler = RandomSampler(train_data)\n",
    "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "  # Create the DataLoader for our validation set\n",
    "  val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "  val_sampler = SequentialSampler(val_data)\n",
    "  val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "  set_seed(42)    # Set seed for reproducibility\n",
    "  bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "  val_loss, val_accuracy ,val_neg_f1, val_pos_f1, microF1, macroF1 = train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n",
    "  acc_per_fold.append(val_accuracy)\n",
    "  loss_per_fold.append(val_loss)\n",
    "  neg_f1_per_fold.append(val_neg_f1)\n",
    "  \n",
    "  pos_f1_per_fold.append(val_pos_f1)\n",
    "  micro_f1_per_fold.append(microF1)\n",
    "  macro_f1_per_fold.append(macroF1)\n",
    "\n",
    "loss = np.mean(loss_per_fold)\n",
    "acc = np.mean(acc_per_fold)\n",
    "negf1= np.mean(neg_f1_per_fold)\n",
    "posf1 = np.mean(pos_f1_per_fold)\n",
    "microf1= np.mean(micro_f1_per_fold)\n",
    "macrof1 = np.mean(macro_f1_per_fold)\n",
    "print(f\" {'Avg Loss':^10} | {'Avg Acc':^8}  |{' avg neg F1':^8}|{'avg pos F1':^8} |{'avg micro F1':^8} |{'avg macro F1':^8} \") \n",
    "print(f\" { loss:^10.6f} | {acc:^9f} | {negf1:^9f} |{posf1:^9f} |{microf1:^9f} |{macrof1:^9f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNZfSDlKM7Wp",
    "outputId": "0448d83c-7556-4133-9891-330ec8d6750f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(tmp1,tmp2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MARBERTonKF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08d39d4473e249f79eb414ab513dd3da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c93737e3f25d4e0fb637a351de5e98e9",
      "max": 1099714,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75c12a52c084408faa49da709f903f9d",
      "value": 1099714
     }
    },
    "0972184606d6419b82aee8c287a54902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6b10caf251c4cf984416c24b2eb6f50",
       "IPY_MODEL_08d39d4473e249f79eb414ab513dd3da",
       "IPY_MODEL_6354d425d93c4541864aee47cc5126b3"
      ],
      "layout": "IPY_MODEL_d7ffc433ccb6417fbea4d91fb840a983"
     }
    },
    "12015d613f294a6aa0bf4132432ca582": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34a4455a785244e9ab998570c8d5dc47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5b16f42d1944db597a2d43165b59305",
      "placeholder": "​",
      "style": "IPY_MODEL_f9416fcb106f4f73acd5f14d0b9e08dd",
      "value": " 701/701 [00:00&lt;00:00, 22.1kB/s]"
     }
    },
    "545072834b3b48a693cbf3b64dbdf306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f972d57e96f7478ab284740acbc3937b",
       "IPY_MODEL_6f80c20809424481b7150c140e9b319d",
       "IPY_MODEL_b374eadace0140e1ba958d470d902bde"
      ],
      "layout": "IPY_MODEL_5beca60916734c21b41b5e2c30ac8b83"
     }
    },
    "558a192fab994a668432e6e467dbd83a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a8c7b5eb9c04e7b8795ca457bd421cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5beca60916734c21b41b5e2c30ac8b83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60e09cdcc9194f8a8a3698714c5b38cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6354d425d93c4541864aee47cc5126b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f117b08a16fa42af99cb904d1dd92624",
      "placeholder": "​",
      "style": "IPY_MODEL_dfe6c2b805b74895a6165cf8b6ec5ea7",
      "value": " 1.05M/1.05M [00:00&lt;00:00, 2.62MB/s]"
     }
    },
    "68609e76bcfc41f483a5254b4a6cf04a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c1d26c956654c5592b1dfc27456e06b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d5dd0093f674d9ca9a7cde27cbae8b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f80c20809424481b7150c140e9b319d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c54a81af6d2d4ed094b77ff9302626cb",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f7b592822844de7ab2c8c6b295ecda0",
      "value": 112
     }
    },
    "713ad769763c4202adab4ea6abe652c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd969592c1ae4d59a48b645d9f928140",
      "placeholder": "​",
      "style": "IPY_MODEL_f5151bbc6e74456b8cda1b579cf86c20",
      "value": "Downloading: 100%"
     }
    },
    "73c6994f01114ebb9fe789e8aab8598e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75c12a52c084408faa49da709f903f9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7608dc94d1d44f64832cb2e1a546b7e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f34bcc4ad0204537a4dc200a58cb9e69",
      "max": 376,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_60e09cdcc9194f8a8a3698714c5b38cd",
      "value": 376
     }
    },
    "7f7b592822844de7ab2c8c6b295ecda0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7fd9fe6f1a5c4a72a38b7f44d1d2804c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85efebbed86146d4b97c9f63aa75af6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87c85f8ec7494da3a38e7660cfbc8d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bfab145dd5d346ed8775e3135af0c476",
      "placeholder": "​",
      "style": "IPY_MODEL_6d5dd0093f674d9ca9a7cde27cbae8b5",
      "value": " 376/376 [00:00&lt;00:00, 11.0kB/s]"
     }
    },
    "8ff4f3ceffd94f07aedb8964ae17ae23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_713ad769763c4202adab4ea6abe652c2",
       "IPY_MODEL_7608dc94d1d44f64832cb2e1a546b7e9",
       "IPY_MODEL_87c85f8ec7494da3a38e7660cfbc8d51"
      ],
      "layout": "IPY_MODEL_925632f0757c4140ac014989a6ff9294"
     }
    },
    "8ff51db0e2354bf2aaf2aa293fc196dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "925632f0757c4140ac014989a6ff9294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93f68c8056e04380b666dffb71adfda1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c1d26c956654c5592b1dfc27456e06b",
      "max": 701,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b295e5f0a65f4812a846c79110d6c3cc",
      "value": 701
     }
    },
    "9733b368628a4211ad48a0a0cfb3cec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f89349e0d65470191ce5590e448a720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a2388be6dd214be4bd038be5ba7ed722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f02b2a71302a41568c5e2e260a2f27f9",
      "placeholder": "​",
      "style": "IPY_MODEL_5a8c7b5eb9c04e7b8795ca457bd421cd",
      "value": " 624M/624M [00:28&lt;00:00, 17.5MB/s]"
     }
    },
    "afad952ca5a94f8c82e32b973aede86d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12015d613f294a6aa0bf4132432ca582",
      "placeholder": "​",
      "style": "IPY_MODEL_9733b368628a4211ad48a0a0cfb3cec4",
      "value": "Downloading: 100%"
     }
    },
    "b295e5f0a65f4812a846c79110d6c3cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2b11cdc374f4409998a01fef891e6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_afad952ca5a94f8c82e32b973aede86d",
       "IPY_MODEL_c238d460699543d6bdf3b610f43e3a1b",
       "IPY_MODEL_a2388be6dd214be4bd038be5ba7ed722"
      ],
      "layout": "IPY_MODEL_f55bb9008c4049fab8b288959e7307fa"
     }
    },
    "b374eadace0140e1ba958d470d902bde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3aae0530a074e29b4ac25de8b23281b",
      "placeholder": "​",
      "style": "IPY_MODEL_f8e066702bc845b0b3d850977780f510",
      "value": " 112/112 [00:00&lt;00:00, 1.41kB/s]"
     }
    },
    "bd01e729cb8946beb0923634a91632a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bfab145dd5d346ed8775e3135af0c476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c238d460699543d6bdf3b610f43e3a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68609e76bcfc41f483a5254b4a6cf04a",
      "max": 654186400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f89349e0d65470191ce5590e448a720",
      "value": 654186400
     }
    },
    "c54a81af6d2d4ed094b77ff9302626cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c93737e3f25d4e0fb637a351de5e98e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd5d70abb3524cdab3b944dd526eb588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e33ea59733af4253b59633287d3d431c",
       "IPY_MODEL_93f68c8056e04380b666dffb71adfda1",
       "IPY_MODEL_34a4455a785244e9ab998570c8d5dc47"
      ],
      "layout": "IPY_MODEL_85efebbed86146d4b97c9f63aa75af6e"
     }
    },
    "cd969592c1ae4d59a48b645d9f928140": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3aae0530a074e29b4ac25de8b23281b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7ffc433ccb6417fbea4d91fb840a983": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfe6c2b805b74895a6165cf8b6ec5ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e33ea59733af4253b59633287d3d431c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ff51db0e2354bf2aaf2aa293fc196dc",
      "placeholder": "​",
      "style": "IPY_MODEL_558a192fab994a668432e6e467dbd83a",
      "value": "Downloading: 100%"
     }
    },
    "e5b16f42d1944db597a2d43165b59305": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6b10caf251c4cf984416c24b2eb6f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc2f38e57e114ba581abf13672fd9f54",
      "placeholder": "​",
      "style": "IPY_MODEL_bd01e729cb8946beb0923634a91632a6",
      "value": "Downloading: 100%"
     }
    },
    "f02b2a71302a41568c5e2e260a2f27f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f117b08a16fa42af99cb904d1dd92624": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f34bcc4ad0204537a4dc200a58cb9e69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5151bbc6e74456b8cda1b579cf86c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f55bb9008c4049fab8b288959e7307fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8e066702bc845b0b3d850977780f510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9416fcb106f4f73acd5f14d0b9e08dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f972d57e96f7478ab284740acbc3937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73c6994f01114ebb9fe789e8aab8598e",
      "placeholder": "​",
      "style": "IPY_MODEL_7fd9fe6f1a5c4a72a38b7f44d1d2804c",
      "value": "Downloading: 100%"
     }
    },
    "fc2f38e57e114ba581abf13672fd9f54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
